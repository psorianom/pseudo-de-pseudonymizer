# pseudo-de-pseudonymizer
Code to transform an already pseudonymized text into pseudo (false) non-anonymized data.
For example, the already pseudonymized text: 
    
    diminution du volume horaire du contrat de travail afin de permettre à chacun de préserver son emploi, le contrat de travail de Mme X... nèe le ... demeurant ..., passant à temps partiel sur une base de 20 heures par semaine par tranches quotidiennes de 4 heures. 

Is converted to:

    diminution du volume horaire du contrat de travail afin de permettre à chacun de préserver son emploi, le contrat de travail de Mme DUPONT nèe le 01 janvier 1940 demeurant 99 rue raoul servant Vaulx-en-Velin 78665 , passant à temps partiel sur une base de 20 heures par semaine par tranches quotidiennes de 4 heures. 



## Introduction

Justice/law related documents are openly published in France through the [Legifrance](https://www.legifrance.gouv.fr/) portal. The documents are pseudonymized following different schemes. Specifically, personal information is replaced by a tag. For example,
the tags `...`, `[...]`, or `xxxxxxxx` are used to replace names, birthdates, addresses, and so on.

In order to train NER models to pseudonyimize new data we need manually annotated examples. This kind of tagged corpus is hard to come by. At the same time, Legifrance offers hundreds of already pseudonymized documents. 

This project aims to distantly-supervise these documents in order to be used as training data. Indeed, while we do not know the true correspondence between a tag, e.g., `...`, and its true entity, we know where it occurred. If we replace these dots tags by false names, false addresses, false birthdates, and so on, we can recreate a false (or pseudo) non-anonymized corpus. 

## Methodology

For the time being, the procedure is done in two steps:

1. We use regexes to replace the dots-tags (`...`) by a corresponding tag (PERPERPER for names, LOCLOCLOC for addresses, and DATEDATEDATE for birthdates)  (`tagger_capp.py`),
2. Then we segment/tokenize the text and replace the new tags by CoNLL IOB tags to effectively create a CoNLL format file which can be used later to train a structured-prediction algorithm (`txt2conll.py`).

Empirically, we know that the most frequently used tag in the documents is the three consecutive dots `...` which is used to replace addresses  birthdates, etc... Nontheless, for names,  the tag `X...` is used for first and last names, where `X` is, we believe, the first letter of the real name. Still, we deal also with `[...]` and `xxxx+`.

### How the pseudo data are generated ?
* LOC: or addresses, are generated by using the name of strees (rues) and communes from the [BAN](https://www.data.gouv.fr/fr/datasets/base-adresse-nationale/) dataset. We generate an address number (random number from 1 to 1000), take a random street, a random commune, a fake postal code (random five figures number), and concatenate everything to come up with a fake address.
* PER: or names, we take a huge list of first and last names and randomly pick one for each PERPERPER instance identified in the previously described step 1.
* DATE: we take a random number from 1 to 31, a random month, and a random year from 1940 to 2000, concatenate it and thus have a new pseudo date.

## Using it

To perform the **first step**, we use:

    python tagger_capp.py <INPUT_FILE> <OUTPUT_FILE>

where `INPUT_FILE` is the file with the text to pseudo-de-psedunonymize, and `OUTPUT_FILE` is the file with the identified `...` tags changed by its corresponding tag. For now this is PER, LOC, and DATE, for last and first names, addresses and birthdates, respectively.

The **second step** is performed by doing:
    
    python txt2conll.py <INPUT_FILE> <OUTPUT_FOLDER>

where `INPUT_FILE` is the file with pseudo-de-psedunonymized text, and `OUTPUT_FOLDER` is the folder where to store the CoNLL formatted file. That is, one word per line and its corresponding tag. The tags PER, LOC, and DATE are changed to X-PER, X-LOC, and X-DATE, where X is either B or I, depending on the position of the word in the annotated sequence (Beginning or already Inside) .

## TODO
This is very preliminal work. Some TODOs are:
1. Test the distance-supervised data with ukpbilstm machin.
2. Make the code more flexible, allow for different tags (automatically discover them from the doc??) 
3. Auto-tag the non-treated ...'s by making a word2vec model and t-sneing those tags.
