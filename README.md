# pseudo-de-pseudonymizer
Code to transform an already pseudonymized text into pseudo (false) non-anonymized NER training data.
For example, the already pseudonymized text (with `...` tags replacing personal data): 
    
    le contrat de travail de Mme X... nèe le ... demeurant ..., passant à temps partiel
    sur une base de 20 heures 
    
Is first converted to:

    le contrat de travail de Mme PERPERPER née le DATEDATEDATE demeurant LOCLOCLOC , passant à temps partiel
    sur une base de 20 heures 
    
And finally, converted to the CoNLL format:

| | | | | | |
|-|-|-|-|-|-|
|  le      | O      | 1940      | I-DATE | 78665   | I-LOC |
| contrat  | O      | demeurant | O      | ,       | O     |
| de       | O      | 99        | B-LOC  | passant | O     |
|  travail | O      | rue       | I-LOC  | à       | O     |
| de       | O      | raoul     | I-LOC  | temps   | O     |
| Mme      | O      | servant   | I-LOC  | partiel | O     |
| DUPONT   | B-PER  | Vaulx     | I-LOC  | sur     | O     |
| nèe      | O      | -         | I-LOC  | une     | O     |
| le       | O      | en        | I-LOC  | base    | O     |
| 01       | B-DATE | -         | I-LOC  | de      | O     |
| janvier  | I-DATE | Velin     | I-LOC  | 20      | O     |
|          |        |           |        | heures  | O     |



## Introduction

Justice/law related documents are openly published in France through the [Legifrance](https://www.legifrance.gouv.fr/) portal. The documents are pseudonymized following different schemes. Specifically, personal information is replaced by a tag. For example,
the tags `...`, `[...]`, or `xxxxxxxx` are used to replace names, birthdates, addresses, and so on. The files (e.g., Cour d'appel) can be found  [here](ftp://echanges.dila.gouv.fr/CAPP/).

In order to train NER models to pseudonyimize new data we need manually annotated examples. This kind of tagged corpus is hard to come by. At the same time, Legifrance offers hundreds of already pseudonymized documents. 

This project aims to distantly-supervise these documents in order to be used as training data. Indeed, while we do not know the true correspondence between a tag, e.g., `...`, and its true entity, we know where it occurred. If we replace these dots tags by false names, false addresses, false birthdates, and so on, we can recreate a false (or pseudo) non-anonymized corpus. 

## Methodology

For the time being, the procedure is done in two steps:
0. Extract the text content from Legifrance justice decisions (`xml2txt.py`)
1. We use regexes to replace the pseudonyms (repeated dots  `...`) by a corresponding tag (PERPERPER for names, LOCLOCLOC for addresses, and DATEDATEDATE for birthdates)  (`tagger_capp.py`),
2. Then we segment/tokenize the text and replace the new tags by CoNLL IOB tags to effectively create a CoNLL format file which can be used later to train a structured-prediction algorithm (`txt2conll.py`). The files separated in train, dev, and test.

Empirically, we know that the most frequently used tag in the documents is the three consecutive dots `...` which is used to replace addresses  birthdates, etc... Nontheless, for names,  the tag `X...` is used for first and last names, where `X` is, we believe, the first letter of the real name. Still, we deal also with `[...]` and `xxxx+`.

### How the pseudo data are generated ?
* LOC: or addresses, are generated by using the name of streets (rues) and communes from the [BAN](https://www.data.gouv.fr/fr/datasets/base-adresse-nationale/) dataset. We generate an address number (random number from 1 to 1000), take a random street, a random commune, a fake postal code (random five figures number), and concatenate everything to come up with a fake address.
* PER: or names, we take a huge list of first and last names and randomly pick one for each PERPERPER instance identified in the previously described step 1.
* DATE: we take a random number from 1 to 31, a random month, and a random year from 1940 to 2000, concatenate it and thus have a new pseudo date.

## Using it

To perform the **first step**, we use:

    python tagger_capp.py <INPUT_FILE> <OUTPUT_FILE>

where `INPUT_FILE` is the file with the text to pseudo-de-psedunonymize, and `OUTPUT_FILE` is the file with the identified `...` tags changed by its corresponding tag. For now this is PER, LOC, and DATE, for last and first names, addresses and birthdates, respectively.

The **second step** is performed by doing:
    
    python txt2conll.py <INPUT_FILE> <OUTPUT_FOLDER>

where `INPUT_FILE` is the file with pseudo-de-psedunonymized text, and `OUTPUT_FOLDER` is the folder where to store the CoNLL formatted file. That is, one word per line and its corresponding tag. The tags PER, LOC, and DATE are changed to X-PER, X-LOC, and X-DATE, where X is either B or I, depending on the position of the word in the annotated sequence (Beginning or already Inside) .

## TODO
This is very preliminal work. Some TODOs are:
1. Test the distance-supervised data with ukpbilstm machin.
2. Make the code more flexible, allow for different tags (automatically discover them from the doc??) 
3. Auto-tag the non-treated ...'s by making a word2vec model and t-sneing those tags.
